{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "li = [12,1,31,1,2121,23,120]\n",
    "# dic = {\n",
    "# }\n",
    "# for i in range(len(li)):\n",
    "#     if dic[str(li[i])]==o:\n",
    "#         dic[str(li[i])]=1\n",
    "#     else:\n",
    "#         dic[str(li[i])]+=1\n",
    "\n",
    "# dic \n",
    "# import numpy as np \n",
    "# # np.unique(li)\n",
    "# ans = []\n",
    "# for i in li:\n",
    "#     li.append(li.count(i))\n",
    "# print(min)\n",
    "\n",
    "# def find(n):\n",
    "#     left,right= 0,len(n)-1\n",
    "#     while left<right:\n",
    "#         mid=left+(right-left)//2\n",
    "#         if mid%2==1:\n",
    "#             mid=mid-1\n",
    "#         if left == \n",
    "\n",
    "# n= [1,1,2,2,3,3,4,4,8,8]\n",
    "# for i in range(0,len(n)-1,2):\n",
    "#     if n[i]!=n[i+1]:\n",
    "#         print(n[i])\n",
    "#         break\n",
    "# else:\n",
    "#     print(n[-1])     \n",
    "\n",
    "# \\\\wsl.localhost\\Ubuntu\\home\\manju_nath_k\\.jdks\\openjdk-23.0.2-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful Soup Documentation — Beautiful Soup 4.4.0 documentation\n"
     ]
    }
   ],
   "source": [
    "url = \"https://beautiful-soup-4.readthedocs.io/en/latest/\"\n",
    "response = requests.get(url)\n",
    "# print(response)\n",
    "raw_code = response.text\n",
    "# print(raw_code)\n",
    "soup = BeautifulSoup(raw_code,\"html.parser\")\n",
    "# print(soup.prettify())\n",
    "print(soup.title.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"reference internal\" href=\"#a-list\">A list</a>, <a class=\"headerlink\" href=\"#a-list\" title=\"Permalink to this headline\">Â¶</a>, <a class=\"reference internal\" href=\"#a-list\">a list</a>, <a class=\"reference internal\" href=\"#a-list\">a list</a>, <a class=\"reference internal\" href=\"#a-list\">a list</a>]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://beautiful-soup-4.readthedocs.io/en/latest/\"\n",
    "raw=requests.get(url)\n",
    "# soup= raw.text\n",
    "ans=BeautifulSoup(raw.text,\"html.parser\")\n",
    "# print(ans.title.string)\n",
    "# one=ans.find(class_=\"rm-presentation\")\n",
    "# one= ans.find(id=\"reference external\")\n",
    "# for i in one:\n",
    "#     print(i)\n",
    "# print(one)\n",
    "# a= ans.select(\"#quick-start\")\n",
    "# for i in a:\n",
    "#     print(i.text)\n",
    "\n",
    "a = ans.select(\".headerlink\")\n",
    "# print(a.text, \"->\",a.get(\"href\"))\n",
    "# print(a)\n",
    "b = ans.select(\"a[href='#a-list']\")\n",
    "print(b)\n",
    "c=ans.select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.amazon.in/s?bbn=84514752031&rh=n%3A84514752031%2Cp_85%3A10440599031&_encoding=UTF8&content-id=amzn1.sym.58c90a12-100b-4a2f-8e15-7c06f1abe2be&pd_rd_r=3f43a2be-c670-4dea-abd4-55bd5ef013e8&pd_rd_w=QPDN0&pd_rd_wg=XQyN2&pf_rd_p=58c90a12-100b-4a2f-8e15-7c06f1abe2be&pf_rd_r=ERNHTMV0ZBQNF4DMZ9E1&ref=pd_hp_d_atf_unk\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "ans = soup.select(\".a-price-whole\")\n",
    "a= ans[0]\n",
    "b=    a.text\n",
    "# for i  in ans:\n",
    "#     print(i)\n",
    "an= b.replace(\",\",\"\")\n",
    "# print(an)\n",
    "\n",
    "w_price = 15000\n",
    "if int(an) < w_price :\n",
    "    print(\"The price is low lets grab\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              Bad Bunny\n",
      "1         Kendrick Lamar\n",
      "2            Teddy Swims\n",
      "3          Morgan Wallen\n",
      "4                    SZA\n",
      "5      Sabrina Carpenter\n",
      "6           Taylor Swift\n",
      "7             Bruno Mars\n",
      "8          Billie Eilish\n",
      "9             Kane Brown\n",
      "10    Tyler, The Creator\n",
      "11         Chappell Roan\n",
      "12         Gracie Abrams\n",
      "13            Zach Bryan\n",
      "14            Jelly Roll\n",
      "15             Shaboozey\n",
      "16           Post Malone\n",
      "17                Hozier\n",
      "18            Mac Miller\n",
      "19            Luke Combs\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "url = \" https://www.billboard.com/charts/artist-100/\" \n",
    "res = requests.get(url )\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "one = soup.select( \" li h3 \")\n",
    "top20 = [song.text[14:][:-5] for song in one[:20]]\n",
    "# print(top20)\n",
    "# print(one.string)\n",
    "sam = [ f\"{son}\" for son in top20]\n",
    "\n",
    "tab= pd.Series(sam)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0\n",
      "0                  100. Toni Erdmann (Maren Ade, 2016)\n",
      "1    100. Requiem for a Dream (Darren Aronofsky, 2000)\n",
      "2                  100. Carlos (Olivier Assayas, 2010)\n",
      "3           99. The Gleaners and I (Agnès Varda, 2000)\n",
      "4                     98. Ten (Abbas Kiarostami, 2002)\n",
      "..                                                 ...\n",
      "96                5. Boyhood (Richard Linklater, 2014)\n",
      "97             4. Spirited Away (Hayao Miyazaki, 2001)\n",
      "98   3. There Will Be Blood (Paul Thomas Anderson, ...\n",
      "99        2. In the Mood for Love (Wong Kar-wai, 2000)\n",
      "100            1. Mulholland Drive (David Lynch, 2001)\n",
      "\n",
      "[101 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://www.imdb.com/search/title/?title_type=feature\"\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "# }\n",
    "# res = requests.get(url,headers= headers)\n",
    "# soup = BeautifulSoup(res.text , \"lxml\")\n",
    "# for i in soup:\n",
    "#     print(i.text)\n",
    "\n",
    "url = \"https://www.bbc.com/culture/article/20160819-the-21st-centurys-100-greatest-films\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "res = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "ans = soup.select(\"p \")   # .sc-eb7bd5f6-0 fYAfXe\n",
    "an = []\n",
    "for i in ans:\n",
    "    res=i.text\n",
    "    if res.startswith(tuple(\"0123456789\")):\n",
    "        an.append(res)\n",
    "one=pd.DataFrame(an)\n",
    "# one.to_csv(\"top_100.csv\")\n",
    "print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no access\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "import os \n",
    "url = \"https://www.ebay.com/b/Rolex/bn_21834331\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "res= requests.get(url)\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "result = soup.select(\"img\")\n",
    "images = []\n",
    "file_name = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"downloaded_images\")\n",
    "os.makedirs(file_name,exist_ok=True)\n",
    "for i in result:\n",
    "    a=i.get(\"src\")\n",
    "    if a.endswith(\"jpg\"):\n",
    "        images.append(a)\n",
    "for i in images:\n",
    "    img=urljoin(url, i)\n",
    "    image=requests.get(img,headers=headers).content\n",
    "    img_path =os.path.join(file_name)\n",
    "    try:\n",
    "        with open(img_path,\"wb\") as img_file:\n",
    "            img_file.write(image)\n",
    "    except PermissionError:\n",
    "        print(\"no access\")\n",
    "    \n",
    "# print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['77,427.00', '77,427.00', '77,427.0077,427.00', '77,427.0077,427.00', '69,000.00', '69,000.00', '77,427.00', '77,427.00', '86,950.00', '86,950.00', '24.00', '24.00', '95,998.00', '95,998.00', '82,950.00', '82,950.00', '83,748.00', '83,748.00', '1,80,690.00', '1,80,690.00', '78,768.00', '78,768.00', '77,427.00', '77,427.00', '85,252.00', '85,252.00', '75,969.00', '75,969.00', '82,950.00', '82,950.00', '83,748.00', '83,748.00', '85,817.00', '85,817.00']\n"
     ]
    }
   ],
   "source": [
    "# with open(\"Day_1_.ipynb\") as dy:\n",
    "#     content = dy.read()\n",
    "#     print(content)\n",
    "url = \"https://www.amazon.in/Hero-PLEASURE-Scooter-Booking-Ex-Showroom/dp/B0D9DLYSFG/?_encoding=UTF8&pd_rd_w=mD9yT&content-id=amzn1.sym.15bbf9a3-916e-4a39-9599-e18ce13d6547&pf_rd_p=15bbf9a3-916e-4a39-9599-e18ce13d6547&pf_rd_r=CA2CNM36WYS5VMMNBKWK&pd_rd_wg=wYTds&pd_rd_r=d8028994-2cb2-472d-b770-f522d92efcac&ref_=pd_hp_d_btf_ls_gwc_pc_en4_\"\n",
    "res= requests.get(url)\n",
    "soup=BeautifulSoup(res.text,\"lxml\")\n",
    "# ans = soup.find_all(class_= \"a-price-whole\")\n",
    "# for i in ans:\n",
    "#     if i.text !=\"0\" :\n",
    "#         print(float(i.text[:-1].replace(\",\",\"\")))\n",
    "ans = soup.find_all(class_=[\"a-price\",\"a-size-base\"])\n",
    "lis=[]\n",
    "for i in ans:\n",
    "    if i.text.startswith(\"₹\"):\n",
    "        lis.append(i.text.split(\"₹\"))\n",
    "# print(lis) \n",
    "two=[]  \n",
    "for j in lis:\n",
    "    for j in j:\n",
    "        if j!=\"\":\n",
    "            two.append(j)\n",
    "print(two)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
